{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pretrainedModel import *\n",
    "from faceRecognition import *\n",
    "import pandas as pd\n",
    "from math import *\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FaceNet pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess, embeddings, images_in, phase_train_in, pnet, rnet, onet = detectionNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up face DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Path of the references faces that will construct the database of faces\n",
    "pathsKnown = [\"/home/sabrine/Pictures/laurene1.jpg\",\n",
    "              \"/home/sabrine/Pictures/laurene2.jpg\",\n",
    "              \"/home/sabrine/Pictures/laurene3.jpg\",\n",
    "              \"/home/sabrine/Pictures/anthony1.jpg\",\n",
    "              \"/home/sabrine/Pictures/anthony2.jpg\",\n",
    "              \"/home/sabrine/Pictures/anthony3.jpg\",\n",
    "              \"/home/sabrine/Pictures/wissem1.jpg\",\n",
    "              \"/home/sabrine/Pictures/wissem2.jpg\",\n",
    "              \"/home/sabrine/Pictures/wissem3.jpg\",\n",
    "              \"/home/sabrine/Pictures/cynthiaq1.jpeg\",\n",
    "              \"/home/sabrine/Pictures/cynthiaq2.jpeg\",\n",
    "              \"/home/sabrine/Pictures/cynthiaq3.jpeg\",\n",
    "              \"/home/sabrine/Pictures/sabrineb1.jpg\",\n",
    "              \"/home/sabrine/Pictures/sabrineb2.jpg\",\n",
    "              \"/home/sabrine/Pictures/sabrineb3.jpg\",\n",
    "             \"/home/sabrine/Pictures/oliverb1.jpg\",\n",
    "             \"/home/sabrine/Pictures/oliver2.jpg\",\n",
    "             \"/home/sabrine/Pictures/oliverb3.jpg\",\n",
    "             \"/home/sabrine/Pictures/lucas1.jpg\",\n",
    "             \"/home/sabrine/Pictures/lucasb2.jpg\",\n",
    "             \"/home/sabrine/Pictures/lucas3.jpg\",\n",
    "             \"/home/sabrine/Pictures/albertob1.jpg\",\n",
    "             \"/home/sabrine/Pictures/albertob2.jpg\",\n",
    "             \"/home/sabrine/Pictures/albertob3.jpg\"]\n",
    "\n",
    "# Creation of identities names\n",
    "names = ['Laurene', 'Laurene', 'Laurene', 'Anthony', 'Anthony', 'Anthony', 'Wissem', 'Wissem', 'Wissem',\n",
    "         'Cynthia', 'Cynthia', 'Cynthia','Sabrine', 'Sabrine', 'Sabrine', 'Oliver', 'Oliver', 'Oliver',\n",
    "         'Lucas', 'Lucas', 'Lucas', 'Alberto', 'Alberto', 'Alberto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# detection parameters\n",
    "minsize = 40 \n",
    "threshold = [ 0.75, 0.75, 0.75 ]\n",
    "factor = 0.709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = embeddingKnownFaces(pathsKnown, names, sess, embeddings, images_in,\n",
    "                   phase_train_in, pnet, rnet, onet,\n",
    "                   minsize, threshold, factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retreive rgbSeq with detection information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "synchronize = pd.read_pickle('synchronization/synchronize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a list of name in the same order of the known embeddings without repetition \n",
    "uniqueNames = []\n",
    "for i in names:\n",
    "    if i not in uniqueNames:\n",
    "        uniqueNames.append(i)\n",
    "print (uniqueNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "FR for all frame and storing of the returned information in the same order as the df synchronize\n",
    "'''\n",
    "\n",
    "bigSmallestArray = []\n",
    "bigCenters = []\n",
    "#scores = [[] for i in range(len(uniqueNames))]\n",
    "embs = []\n",
    "rgb = []\n",
    "faceX = []\n",
    "faceY = []\n",
    "blurScore = []\n",
    "#frontalBool = []\n",
    "\n",
    "for seq in synchronize.rgbSeq.unique():\n",
    "    print seq\n",
    "    \n",
    "    #Path of the frames\n",
    "    #path = '/home/sabrine/notebook/framesRGB2/' + str(seq) + '.jpg'\n",
    "    #path = '/home/sabrine/notebook/framesRGB2/' + '177' + '.jpg'\n",
    "    \n",
    "    # List of names, coordinates and distances of the FR process\n",
    "    fr = faceRecognition(pathsKnown, names, path, sess, embeddings, images_in, phase_train_in, pnet, rnet, onet, df)\n",
    "    #print fr[2]\n",
    "    # fr[2] is a np array of the embeddings : shape (nb of emb, 128) with 128 the number of feature\n",
    "    smallestArray = fr[0]\n",
    "    centers = fr[1]\n",
    "    emb = fr[2]\n",
    "    blur = fr[3]\n",
    "    #frontal = fr[4]\n",
    "\n",
    "    # check if at least one face has been detected\n",
    "    if len(fr[0]) > 0:\n",
    "        for i in range(smallestArray.shape[1]):\n",
    "            #for j in range(len(scores)):\n",
    "                #scores[j].append(smallestArray[j, i])\n",
    "            bigCenters.append(centers[i])\n",
    "            faceX.append(centers[i][0])\n",
    "            faceY.append(centers[i][1])\n",
    "            embs.append(emb[i])\n",
    "            rgb.append(seq)\n",
    "            blurScore.append(blur[i])\n",
    "            #frontalBool.append(frontal[i])\n",
    "    else:\n",
    "        # So the index of rgb, bigCenters and scores will be the same as synchronize.rgbSeq.unique()\n",
    "        # It will simplify the join process of these 2 df\n",
    "        rgb.append(np.nan)\n",
    "        faceX.append(np.nan)\n",
    "        faceY.append(np.nan)\n",
    "        embs.append(np.nan)\n",
    "        blurScore.append(np.nan)\n",
    "        #frontalBool.append(0)\n",
    "        bigCenters.append(np.nan)\n",
    "        #for j in range(len(scores)):\n",
    "        #        scores[j].append(np.nan)\n",
    "    \n",
    "    print '*************'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if all list has the same size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(faceY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(faceX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(bigCenters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(blurScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of the df faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "faces = pd.DataFrame(np.asarray([faceX, faceY, rgb, blurScore]).T, \n",
    "                     columns=['faceX', 'faceY', 'rgb', 'blurScore'])\n",
    "faces['embs'] = embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the result in pickle algorithm\n",
    "faces.to_pickle('faces')\n",
    "np.save('uniqueName', uniqueNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
