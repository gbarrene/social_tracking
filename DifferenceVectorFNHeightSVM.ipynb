{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creation of dataset : features and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracking = pd.read_pickle('MLbodyFace').dropna()\n",
    "database = pd.read_pickle('database').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracking.drop(['seq', 'id', 'traSeq', 'trackId', 'rgbSeq'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "database.rename(columns={'index': 'name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We prepare the other dataset to be append to the big one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sabrine = pd.read_pickle('sabrine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove useless column - so both DataFrame have the same column \n",
    "sabrine.drop(['seq', 'id', 'traSeq', 'trackId', 'rgbSeq'], axis=1, inplace=True)\n",
    "sabrine.rename(columns={'name': 'GroundTrue'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Height normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As max height equal 2.3 and min height is 1.3, we just have to shift it to have value in [-0.5, 0.5] and multiply the value by 2 to have value in [-1, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracking.height = tracking.height.apply(lambda x : (x - 1.8)*2)\n",
    "database.height = database.height.apply(lambda x : (x - 1.8)*2)\n",
    "sabrine.height = sabrine.height.apply(lambda x : (x - 1.8)*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of embeddings information into different column to feed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract embedding informations and rearrange it into columns \n",
    "#(one column for each features - 128 columns in total)\n",
    "em = [[] for i in range(len(tracking.iloc[0].embedding))]\n",
    "\n",
    "for index, r in tracking.iterrows():\n",
    "    for column in range (len(tracking.iloc[0].embedding)):\n",
    "         em[column].append(r.embedding[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Insert nex feature's columns into dataframe\n",
    "for column in range (len(tracking.iloc[0].embedding)):\n",
    "    tracking[column] = em[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop unuseful column\n",
    "tracking.drop('embedding', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Append both DataFrame - got good amount of information for Sabrine as well\n",
    "tracking = tracking.append(sabrine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of dataset for label 1\n",
    "Creation of dataframe with the same person information/features for two different detection.\n",
    "Will be labeled as 1 (label for the same person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group by name - then work on one group to create same person dataset\n",
    "groupBy = tracking.groupby('GroundTrue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Return DF of pair of embeddings + bluriness + distance\n",
    "# Data augmentation between \n",
    "def same(name, group, oneLenght):\n",
    "    listToConcatSame = []\n",
    "    \n",
    "    for index, r in group.reset_index().drop('index', 1).iterrows():\n",
    "        base = database[database.name == name]\n",
    "        base.drop('name', 1, inplace=True)\n",
    "        \n",
    "        # Need to modify columns order to have the same for every sample (from DB and from detection)\n",
    "        cols = base.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        base = base[cols]\n",
    "        \n",
    "        # Print percentage since could be long:\n",
    "        #percentage = index * 100 / len(group)\n",
    "        #if percentage % 10 == 0 :\n",
    "            #print str(percentage) + \"%\"\n",
    "\n",
    "        # Cosine similarity\n",
    "        temp = r.drop(['GroundTrue', 'trackX', 'trackY', 'trackW', 'trackH', 'distance', 'blur'])\n",
    "        difference = np.asarray(base.subtract(temp)).squeeze()\n",
    "        listToConcatSame.append(difference)\n",
    "        \n",
    "        # add number of ones\n",
    "        oneLenght = oneLenght + difference.shape[0]\n",
    "        \n",
    "    return np.asarray(listToConcatSame), oneLenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Same person dataset\n",
    "listToConcat = []\n",
    "oneLenght = 0\n",
    "for name, group in groupBy:\n",
    "    print name\n",
    "    differences, oneLenght = same(name, group, oneLenght)\n",
    "    listToConcat.append(differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creation of dataset for label 0\n",
    "Creation of dataframe of pair of different person information/features.\n",
    "Will be labeled as 0 (label for two different persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def different(name, group, zeroLenght):\n",
    "    listToConcatDiff = []\n",
    "    \n",
    "    for index, r in group.reset_index().drop('index', 1).iterrows():\n",
    "        base = database[database.name != name]\n",
    "        base.drop('name', 1, inplace=True)\n",
    "        \n",
    "        # Display percentage ince could be long\n",
    "        #percentage = index * 100 / len(group)\n",
    "        #if percentage % 20 == 0 :\n",
    "            #print str(percentage) + \"%\"\n",
    "            \n",
    "        # Need to modify columns order to have the same for every sample (from DB and from detection)\n",
    "        cols = base.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        base = base[cols]\n",
    "            \n",
    "        # Cosine similarity\n",
    "        temp = r.drop(['GroundTrue', 'trackX', 'trackY', 'trackW', 'trackH', 'distance', 'blur'])\n",
    "        difference = np.asarray(base.subtract(temp)).squeeze()\n",
    "        listToConcatDiff.append(difference)\n",
    "        zeroLenght = zeroLenght + difference.shape[0]\n",
    "        \n",
    "    return np.asarray(listToConcatDiff).squeeze(), zeroLenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Same person dataset\n",
    "zeroLenght = 0\n",
    "for name, group in groupBy:\n",
    "    print name\n",
    "    cosines, zeroLenght = different(name, group, zeroLenght)\n",
    "    listToConcat.append(cosines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creation of the features matrix and label vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newList = []\n",
    "for e in listToConcat:\n",
    "    new = e.reshape(-1, 129)\n",
    "    for i in range(new.shape[0]):\n",
    "        newList.append(new[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.asarray(newList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.concatenate([np.ones(oneLenght), np.zeros(zeroLenght)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc = SVC(C=100, gamma=0.001, degree=3, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross = cross_val_score(svc, X, y, cv=10, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search to tune SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = [\n",
    "  {'C': [100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf'], 'degree': [2, 3, 4]},\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(svc, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.get_params(deep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad, so I will test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc = SVC(C=100, gamma=0.001, degree=3, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y, svc.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Best metric to evaluate score\n",
    "f1_score(y, svc.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this model shoudl be better then the simple cosine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "#filename = 'svc.sav'\n",
    "#svc = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "folderPath = '/home/sabrine/social_tracking/models/svcEmbeddingHeight/'\n",
    "filename = 'svc.sav'\n",
    "pickle.dump(svc, open(folderPath + filename, 'wb'))\n",
    "pickle.dump(X.reshape(-1, 1), open(folderPath + 'X', 'wb'))\n",
    "pickle.dump(y, open(folderPath + 'y', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
